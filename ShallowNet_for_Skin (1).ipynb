{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import from kaggle (Kagglehub provided code)"
      ],
      "metadata": {
        "id": "2DcG5WWmlC2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"kmader/skin-cancer-mnist-ham10000\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISRLiIWxHygv",
        "outputId": "e88d4d19-de6c-415c-bea3-f7f2d8db2bc3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /kaggle/input/skin-cancer-mnist-ham10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read and build model"
      ],
      "metadata": {
        "id": "T2k08ZYrlSq3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9_xZbLilGAwu",
        "outputId": "b41bfafa-7067-4ce4-8d6a-b9109fe2d726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10015/10015 [02:35<00:00, 64.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected classes: ['Actinic Keratoses', 'Basal Cell Carcinoma', 'Benign Keratosis', 'Dermatofibroma', 'Melanocytic Nevus', 'Melanoma', 'Vascular Lesion']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │      \u001b[38;5;34m4,864\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │     \u001b[38;5;34m36,928\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │    \u001b[38;5;34m204,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m512\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │    \u001b[38;5;34m147,584\u001b[0m │ batch_normalizat… │\n",
              "│                     │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m,  │        \u001b[38;5;34m512\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m128\u001b[0m)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │      \u001b[38;5;34m1,351\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,864</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ batch_normalizat… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_average_p… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,351</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m397,191\u001b[0m (1.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">397,191</span> (1.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m396,423\u001b[0m (1.51 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">396,423</span> (1.51 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m768\u001b[0m (3.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> (3.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 40ms/step - accuracy: 0.5037 - loss: 1.4581 - val_accuracy: 0.6690 - val_loss: 0.9740\n",
            "Epoch 2/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6750 - loss: 0.9233 - val_accuracy: 0.3525 - val_loss: 1.7217\n",
            "Epoch 3/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6819 - loss: 0.8957 - val_accuracy: 0.1543 - val_loss: 2.6932\n",
            "Epoch 4/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6782 - loss: 0.8951 - val_accuracy: 0.1118 - val_loss: 11.1204\n",
            "Epoch 5/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6894 - loss: 0.8328 - val_accuracy: 0.1478 - val_loss: 5.6512\n",
            "Epoch 6/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6965 - loss: 0.8402 - val_accuracy: 0.4618 - val_loss: 1.7781\n",
            "Epoch 7/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7066 - loss: 0.8112 - val_accuracy: 0.6780 - val_loss: 1.0054\n",
            "Epoch 8/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.6999 - loss: 0.8036 - val_accuracy: 0.7109 - val_loss: 0.8440\n",
            "Epoch 9/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7053 - loss: 0.7961 - val_accuracy: 0.5916 - val_loss: 2.0036\n",
            "Epoch 10/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7085 - loss: 0.7826 - val_accuracy: 0.6695 - val_loss: 1.1115\n",
            "Epoch 11/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7109 - loss: 0.7773 - val_accuracy: 0.3595 - val_loss: 1.7809\n",
            "Epoch 12/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7168 - loss: 0.7664 - val_accuracy: 0.6865 - val_loss: 1.0307\n",
            "Epoch 13/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7161 - loss: 0.7657 - val_accuracy: 0.5582 - val_loss: 1.8003\n",
            "Epoch 14/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7162 - loss: 0.7600 - val_accuracy: 0.6455 - val_loss: 2.9057\n",
            "Epoch 15/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7198 - loss: 0.7586 - val_accuracy: 0.3864 - val_loss: 2.1529\n",
            "Epoch 16/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7247 - loss: 0.7468 - val_accuracy: 0.6905 - val_loss: 1.1676\n",
            "Epoch 17/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7257 - loss: 0.7444 - val_accuracy: 0.7269 - val_loss: 0.7657\n",
            "Epoch 18/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7366 - loss: 0.7199 - val_accuracy: 0.7184 - val_loss: 0.7763\n",
            "Epoch 19/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7301 - loss: 0.7335 - val_accuracy: 0.7109 - val_loss: 0.8787\n",
            "Epoch 20/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7340 - loss: 0.7242 - val_accuracy: 0.7294 - val_loss: 0.8017\n",
            "Epoch 21/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7358 - loss: 0.7203 - val_accuracy: 0.7039 - val_loss: 1.0748\n",
            "Epoch 22/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7323 - loss: 0.7239 - val_accuracy: 0.7079 - val_loss: 0.8421\n",
            "Epoch 23/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7346 - loss: 0.7148 - val_accuracy: 0.7089 - val_loss: 0.8840\n",
            "Epoch 24/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7321 - loss: 0.7065 - val_accuracy: 0.6710 - val_loss: 1.0673\n",
            "Epoch 25/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7345 - loss: 0.7046 - val_accuracy: 0.6985 - val_loss: 0.9283\n",
            "Epoch 26/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7395 - loss: 0.7000 - val_accuracy: 0.6990 - val_loss: 0.9631\n",
            "Epoch 27/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7458 - loss: 0.6942 - val_accuracy: 0.6950 - val_loss: 0.9333\n",
            "Epoch 28/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7275 - loss: 0.7059 - val_accuracy: 0.6350 - val_loss: 1.5313\n",
            "Epoch 29/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7441 - loss: 0.6857 - val_accuracy: 0.7204 - val_loss: 0.7693\n",
            "Epoch 30/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7463 - loss: 0.6832 - val_accuracy: 0.6296 - val_loss: 1.5358\n",
            "Epoch 31/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7445 - loss: 0.6796 - val_accuracy: 0.7000 - val_loss: 0.9350\n",
            "Epoch 32/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7409 - loss: 0.6836 - val_accuracy: 0.7279 - val_loss: 0.8423\n",
            "Epoch 33/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7539 - loss: 0.6630 - val_accuracy: 0.7139 - val_loss: 0.8414\n",
            "Epoch 34/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7452 - loss: 0.6767 - val_accuracy: 0.4958 - val_loss: 1.7475\n",
            "Epoch 35/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7601 - loss: 0.6515 - val_accuracy: 0.5691 - val_loss: 1.1916\n",
            "Epoch 36/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7483 - loss: 0.6773 - val_accuracy: 0.7599 - val_loss: 0.6824\n",
            "Epoch 37/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7558 - loss: 0.6725 - val_accuracy: 0.6415 - val_loss: 1.1002\n",
            "Epoch 38/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7550 - loss: 0.6614 - val_accuracy: 0.3270 - val_loss: 5.3829\n",
            "Epoch 39/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7552 - loss: 0.6650 - val_accuracy: 0.7334 - val_loss: 0.7750\n",
            "Epoch 40/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7576 - loss: 0.6542 - val_accuracy: 0.7489 - val_loss: 0.7507\n",
            "Epoch 41/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7582 - loss: 0.6484 - val_accuracy: 0.6585 - val_loss: 1.0706\n",
            "Epoch 42/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7651 - loss: 0.6361 - val_accuracy: 0.6455 - val_loss: 3.8740\n",
            "Epoch 43/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7688 - loss: 0.6212 - val_accuracy: 0.6226 - val_loss: 1.0431\n",
            "Epoch 44/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7681 - loss: 0.6237 - val_accuracy: 0.7114 - val_loss: 0.9195\n",
            "Epoch 45/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7598 - loss: 0.6446 - val_accuracy: 0.6016 - val_loss: 1.2307\n",
            "Epoch 46/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7677 - loss: 0.6267 - val_accuracy: 0.5457 - val_loss: 3.5118\n",
            "Epoch 47/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7664 - loss: 0.6234 - val_accuracy: 0.5397 - val_loss: 1.4079\n",
            "Epoch 48/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7681 - loss: 0.5995 - val_accuracy: 0.6605 - val_loss: 2.7718\n",
            "Epoch 49/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7714 - loss: 0.6227 - val_accuracy: 0.7379 - val_loss: 0.7282\n",
            "Epoch 50/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7801 - loss: 0.6050 - val_accuracy: 0.6815 - val_loss: 1.5692\n",
            "Epoch 51/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7750 - loss: 0.6076 - val_accuracy: 0.7529 - val_loss: 0.7376\n",
            "Epoch 52/80\n",
            "\u001b[1m501/501\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 22ms/step - accuracy: 0.7776 - loss: 0.5950 - val_accuracy: 0.5342 - val_loss: 1.6810\n",
            "Epoch 53/80\n",
            "\u001b[1m157/501\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 20ms/step - accuracy: 0.7691 - loss: 0.6210"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "# Config\n",
        "# Same as S-Net paper\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 80\n",
        "DATASET_ROOT = Path(path)\n",
        "# 2 folders from dataset\n",
        "IMAGE_PART_1 = DATASET_ROOT / \"HAM10000_images_part_1\"\n",
        "IMAGE_PART_2 = DATASET_ROOT / \"HAM10000_images_part_2\"\n",
        "\n",
        "# Load data\n",
        "# Full name for each label\n",
        "DX_LABEL_MAP = {\n",
        "    'nv': \"Melanocytic Nevus\",\n",
        "    'mel': \"Melanoma\",\n",
        "    'bkl': \"Benign Keratosis\",\n",
        "    'bcc': \"Basal Cell Carcinoma\",\n",
        "    'akiec': \"Actinic Keratoses\",\n",
        "    'vasc': \"Vascular Lesion\",\n",
        "    'df': \"Dermatofibroma\"\n",
        "}\n",
        "\n",
        "# Load CSV\n",
        "df = pd.read_csv(DATASET_ROOT / \"HAM10000_metadata.csv\")\n",
        "df['diagnosis_full'] = df['dx'].map(DX_LABEL_MAP)\n",
        "\n",
        "# Map label names to integers\n",
        "class_names = sorted(df['diagnosis_full'].unique())\n",
        "# for name in class names\n",
        "label_to_idx = {name: i for i, name in enumerate(class_names)}\n",
        "df['label_idx'] = df['diagnosis_full'].map(label_to_idx)\n",
        "\n",
        "# Find image path from both folders\n",
        "def find_image_path(image_id):\n",
        "    for folder in [IMAGE_PART_1, IMAGE_PART_2]:\n",
        "        path = folder / f\"{image_id}.jpg\"\n",
        "        if path.exists():\n",
        "            return path\n",
        "    return None\n",
        "\n",
        "# apply image map\n",
        "df[\"image_path\"] = df[\"image_id\"].apply(find_image_path)\n",
        "df = df[df[\"image_path\"].notnull()]  # filter missing\n",
        "\n",
        "# Load image and Label\n",
        "\n",
        "images, labels = [], []\n",
        "print(\"Loading images...\")\n",
        "# for col, row in image pixel\n",
        "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "    img = Image.open(row[\"image_path\"]).convert(\"RGB\").resize((IMG_SIZE, IMG_SIZE))\n",
        "    images.append(np.array(img) / 255.0)\n",
        "    labels.append(row[\"label_idx\"])\n",
        "\n",
        "images = np.array(images, dtype=np.float32)\n",
        "labels = to_categorical(labels, num_classes = len(class_names))\n",
        "\n",
        "# Split and convert to tf.data\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(images, labels, test_size = 0.2, stratify=np.argmax(labels, axis = 1), random_state = 42)\n",
        "\n",
        "# tensor slice data\n",
        "train = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "val = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "NUM_CLASSES = len(class_names)\n",
        "print(f\"Detected classes: {class_names}\")\n",
        "\n",
        "# Build the shallow model (S-Net)\n",
        "\n",
        "# Same as the paper\n",
        "def shallow_model(input_shape = (IMG_SIZE, IMG_SIZE, 3), num_classes = NUM_CLASSES):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Block 1 module\n",
        "    x = layers.Conv2D(64, 5, padding = 'same', activation = 'relu')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(64, 3, padding = 'same', activation = 'relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    feat1 = x\n",
        "\n",
        "    x = layers.MaxPooling2D(pool_size=(2, 2))(feat1)\n",
        "\n",
        "    # Block 2 module\n",
        "    x = layers.Conv2D(128, 5, padding = 'same', activation = 'relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv2D(128, 3, padding = 'same', activation = 'relu')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    feat2 = x\n",
        "\n",
        "    gap1 = layers.GlobalAveragePooling2D()(feat1)\n",
        "    gap2 = layers.GlobalAveragePooling2D()(feat2)\n",
        "    merged = layers.concatenate([gap1, gap2])\n",
        "    merged = layers.Dropout(0.5)(merged)\n",
        "\n",
        "    outputs = layers.Dense(num_classes, activation = 'softmax')(merged)\n",
        "    return models.Model(inputs, outputs)\n",
        "\n",
        "model = shallow_model()\n",
        "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "model.summary()\n",
        "\n",
        "# Train\n",
        "\n",
        "history = model.fit(train, validation_data = val, epochs = EPOCHS)\n",
        "\n",
        "# Show training\n",
        "\n",
        "plt.plot(history.history['accuracy'], label = 'Train')\n",
        "plt.plot(history.history['val_accuracy'], label = 'Val')\n",
        "plt.title(\"Training Accuracy\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# save model\n",
        "model.save(\"shallow_skin_model.h5\")\n",
        "\n",
        "# Predict function will be used for single image when connect to interface\n",
        "\n",
        "def predict_image(image_path):\n",
        "    img = tf.keras.utils.load_img(image_path, target_size = (IMG_SIZE, IMG_SIZE))\n",
        "    img = tf.keras.utils.img_to_array(img) / 255.0\n",
        "    img = tf.expand_dims(img, axis = 0)\n",
        "    preds = model.predict(img)[0]\n",
        "    pred_idx = tf.argmax(preds).numpy()\n",
        "    pred_class = class_names[pred_idx]\n",
        "    confidence = tf.reduce_max(preds).numpy()\n",
        "    print(f\"Prediction: {pred_class} ({confidence:.2%})\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Validation Accuracy"
      ],
      "metadata": {
        "id": "Otglso3tmuqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get predictions on the validation set\n",
        "y_pred_probs = model.predict(X_val, batch_size=BATCH_SIZE)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "# Save as val when changing the modle above\n",
        "val_images = X_val\n",
        "\n",
        "# Map class index to label name\n",
        "idx_to_label = {i: name for i, name in enumerate(class_names)}\n",
        "\n",
        "# Sample 25 indices randomly\n",
        "sample_indices = random.sample(range(len(val_images)), 25)\n",
        "\n",
        "# Plot predictions\n",
        "plt.figure(figsize=(15, 15))\n",
        "for i, idx in enumerate(sample_indices):\n",
        "    image = val_images[idx]\n",
        "    true_label = idx_to_label[y_true[idx]]\n",
        "    pred_label = idx_to_label[y_pred[idx]]\n",
        "    confidence = y_pred_probs[idx][y_pred[idx]]\n",
        "    correct = (y_true[idx] == y_pred[idx])\n",
        "\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    title_color = 'green' if correct else 'red'\n",
        "    plt.title(\n",
        "        f\"Pred: {pred_label} ({confidence:.1%})\\nTrue: {true_label}\",\n",
        "        color=title_color,\n",
        "        fontsize=9\n",
        "    )\n",
        "\n",
        "plt.suptitle(\"Validation Images with Predicted vs Ground Truth Labels\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.92)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "3fUiLcT5NB6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications import MobileNetV2, ResNet50\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_pre\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input as resnet_pre\n",
        "import time\n",
        "\n",
        "# Apply model-specific preprocessing\n",
        "X_val_mobilenet = mobilenet_pre(X_val.copy() * 255.0)\n",
        "X_val_resnet = resnet_pre(X_val.copy() * 255.0)\n",
        "\n",
        "# Helper function to build benchmarking models\n",
        "def build_backbone_model(backbone_fn, preprocess_version = 'default'):\n",
        "    base_model = backbone_fn(\n",
        "        include_top=False,\n",
        "        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n",
        "        weights = 'imagenet'\n",
        "    )\n",
        "    # No compare yet, just train\n",
        "    base_model.trainable = False\n",
        "    # Force each layer to be similar to my model\n",
        "    inputs = layers.Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
        "\n",
        "    # Construct model with similar input\n",
        "    if preprocess_version == 'mobilenet':\n",
        "        x = mobilenet_pre(inputs * 255.0)\n",
        "    elif preprocess_version == 'resnet':\n",
        "        x = resnet_pre(inputs * 255.0)\n",
        "    else:\n",
        "        x = inputs\n",
        "\n",
        "    x = base_model(x, training=False)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    outputs = layers.Dense(NUM_CLASSES, activation = 'softmax')(x)\n",
        "    model = models.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Build models to compare with\n",
        "mobilenet_model = build_backbone_model(MobileNetV2, preprocess_version = 'mobilenet')\n",
        "resnet_model = build_backbone_model(ResNet50, preprocess_version = 'resnet')\n",
        "\n",
        "# Run same epoch and optmizer\n",
        "for model in [mobilenet_model, resnet_model]:\n",
        "    model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train models\n",
        "mobilenet_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
        "resnet_model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS)\n",
        "\n",
        "# Benchmark accuracy and throughput\n",
        "def benchmark(model, X_val_input, y_val):\n",
        "    # Accuracy\n",
        "    loss, acc = model.evaluate(X_val_input, y_val, verbose = 0)\n",
        "\n",
        "    # Throughput (inference on a 64-image batch)\n",
        "    batch = X_val_input[:64]\n",
        "    start = time.time()\n",
        "    _ = model.predict(batch)\n",
        "    # Check duration in terms of time stamp\n",
        "    duration = time.time() - start\n",
        "    # images per second\n",
        "    throughput = 64 / duration\n",
        "\n",
        "    return acc, throughput\n",
        "\n",
        "# Benchmark each model\n",
        "acc_snet, throughput_snet = benchmark(model, X_val, y_val)\n",
        "acc_mobile, throughput_mobile = benchmark(mobilenet_model, X_val_mobilenet, y_val)\n",
        "acc_resnet, throughput_resnet = benchmark(resnet_model, X_val_resnet, y_val)\n",
        "\n",
        "# Print results\n",
        "print(\"Benchmark Results (64-image batch):\")\n",
        "print(f\"S-Net:        Accuracy = {acc_snet:.2%}, Throughput = {throughput_snet:.2f} img/s\")\n",
        "print(f\"MobileNetV2:  Accuracy = {acc_mobile:.2%}, Throughput = {throughput_mobile:.2f} img/s\")\n",
        "print(f\"ResNet50:     Accuracy = {acc_resnet:.2%}, Throughput = {throughput_resnet:.2f} img/s\")\n"
      ],
      "metadata": {
        "id": "5vunkQTfV8gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same thing as above\n",
        "# Random images\n",
        "sample_indices = random.sample(range(len(X_val)), 25)\n",
        "\n",
        "# For each model\n",
        "y_pred_snet = np.argmax(model.predict(X_val, batch_size=BATCH_SIZE), axis=1)\n",
        "y_pred_mobile = np.argmax(mobilenet_model.predict(X_val_mobilenet, batch_size=BATCH_SIZE), axis=1)\n",
        "y_pred_resnet = np.argmax(resnet_model.predict(X_val_resnet, batch_size=BATCH_SIZE), axis=1)\n",
        "# Ground truth\n",
        "y_true = np.argmax(y_val, axis=1)\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(3, 25, figsize=(25, 6))\n",
        "\n",
        "# Ensure label map\n",
        "idx_to_label = {i: name for i, name in enumerate(class_names)}\n",
        "\n",
        "# For each model\n",
        "for col, idx in enumerate(sample_indices):\n",
        "    image = X_val[idx]\n",
        "    true_label = idx_to_label[y_true[idx]]\n",
        "\n",
        "    # Snet\n",
        "    pred_label_snet = idx_to_label[y_pred_snet[idx]]\n",
        "    correct_snet = (y_true[idx] == y_pred_snet[idx])\n",
        "    conf_snet = np.max(model.predict(X_val[idx:idx+1]))\n",
        "    axes[0, col].imshow(image)\n",
        "    axes[0, col].axis('off')\n",
        "    axes[0, col].set_title(f\"{pred_label_snet}\\n({conf_snet:.0%})\", color  = 'green' if correct_snet else 'red', fontsize=8)\n",
        "\n",
        "    # MobileNetV2\n",
        "    pred_label_mobile = idx_to_label[y_pred_mobile[idx]]\n",
        "    correct_mobile = (y_true[idx] == y_pred_mobile[idx])\n",
        "    conf_mobile = np.max(mobilenet_model.predict(X_val_mobilenet[idx:idx+1]))\n",
        "    axes[1, col].imshow(image)\n",
        "    axes[1, col].axis('off')\n",
        "    axes[1, col].set_title(f\"{pred_label_mobile}\\n({conf_mobile:.0%})\", color  = 'green' if correct_mobile else 'red', fontsize=8)\n",
        "\n",
        "    # ResNet50\n",
        "    pred_label_resnet = idx_to_label[y_pred_resnet[idx]]\n",
        "    correct_resnet = (y_true[idx] == y_pred_resnet[idx])\n",
        "    conf_resnet = np.max(resnet_model.predict(X_val_resnet[idx:idx+1]))\n",
        "    axes[2, col].imshow(image)\n",
        "    axes[2, col].axis('off')\n",
        "    axes[2, col].set_title(f\"{pred_label_resnet}\\n({conf_resnet:.0%})\", color  = 'green' if correct_resnet else 'red', fontsize=8)\n",
        "\n",
        "# Set each model into each axis\n",
        "axes[0, 0].set_ylabel(\"S-Net\", fontsize=12)\n",
        "axes[1, 0].set_ylabel(\"MobileNetV2\", fontsize=12)\n",
        "axes[2, 0].set_ylabel(\"ResNet50\", fontsize=12)\n",
        "\n",
        "# Plot model\n",
        "plt.suptitle(\"Model Predictions on 25 Sample Validation Images\\n(Green: Correct, Red: Incorrect)\", fontsize=16)\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(top=0.82)\n",
        "plt.show()\n",
        "\n",
        "# Ran the same thing again in the run, deleted the duplicated half for clarity."
      ],
      "metadata": {
        "id": "q3960sS0-TPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iw00DgimjRJS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}